#!/usr/bin/env python
## Author: Mark Sutherland, (C) 2020

# my includes
from components.closed_loop_gen import ClosedLoopLoadGen
from components.rpc_core import DynamicUServCore

# simpy includes
from my_simpy.src.simpy import Environment
from my_simpy.src.simpy.resources.store import Store

# python environment includes
import argparse
from hdrh.histogram import HdrHistogram
from math import floor

NUM_FUNCS_ASSUMED_DELETEME = 2

def run_exp(arg_string):
    parser = argparse.ArgumentParser(description='Experiment to validate service times predicted by constant CPI + instr stalls')
    parser.add_argument('--WorkingSetFile',type=str,help="File containing a pickled dictionary of function working sets.",default='func_wsets.p')
    parser.add_argument('--FuncTraceFile',type=str,help="File containing a csv which defines the trace of functions generated by the load generator.",default='func_trace.csv')
    parser.add_argument('--CacheSize',type=int,help="Size of an L1 cache in KB. Default = 64",default=64*1024)
    parser.add_argument('--HistoryDepth',type=int,help="Depth of per-core RPC history stored by dispatcher. Default = 16",default=16)
    args = parser.parse_args(arg_string.split())

    # TODO: Restore the working sets from the pickled file - for now, make synthetic ones
    w_set = {}
    addr_base = 0xabcd0000
    for i in range(NUM_FUNCS_ASSUMED_DELETEME):
        w = []
        for j in range(10):
            w.append(addr_base)
            addr_base += 4
        addr_base -= 0x20 # gives some overlap between each one
        w_set[i] = w

    print(w_set)

    # Create the simpy environment needed by all components beneath it
    env = Environment()

    # Make latency store from 100ns to 100000ns, precision of 0.01%
    latency_store = HdrHistogram(100,100000,4)

    # Make queue, load gen, and core
    event_queue = Store(env) # to pass incoming load from generator to core
    lgen = ClosedLoopLoadGen(env,event_queue,args.FuncTraceFile)
    core = DynamicUServCore(env,0,event_queue,latency_store,lgen,w_set,args.CacheSize,args.HistoryDepth,closed_loop = True)
    lgen.set_core(core)

    # Run
    env.run()

    # Get results
    rd = {}
    percentiles = [ 50, 70, 90, 95, 99, 99.9 ]
    for p in percentiles:
        rd[p] = float(latency_store.get_value_at_percentile(p)) / 1000 # return in us
    return rd
